{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bohemian Alligators</h1><br>\n",
    "The group formed in 2018, and though their one and only motive is to create a deep learning masterpiece, their name truly sounds like a funky alternative-rock band's name. They are well known for their passion for everything they get into, and their love for the good-old belgian chocolate ice cream.\n",
    "<br>\n",
    "The Members Are:<br>\n",
    "Beáta Csilla Kovács- the one who always stays calm (she would probably be the singer)<br>\n",
    "Csenge Kilián - the one who has only one first name (she would probably be the bass guitarist)\n",
    "\n",
    "You can read more on the nature of alligators here:\n",
    "https://en.wikipedia.org/wiki/Alligator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> About The Data </h1><br>\n",
    "After considering other datasets as well, our choice fell on the dataset collected and annotated by Berkeley university. \n",
    "It's huge. So we decided to initially only deal with the first 100 samples of segmentated data, but later on we plan to include more.\n",
    "You can download the whole dataset on the following link:\n",
    "http://bdd-data.berkeley.edu/\n",
    "The licence is included at the end of readme of our github repo.\n",
    "\n",
    "Some of the reasons we chose to work with <b>UC Berkerley's dataset</b> are:\n",
    "1. It covers a wide range of driving conditions both regarding daytime and weather\n",
    "2. There are over 10,000 samples and corresponding <b>pixel-level annotations for both class-level and instance-level segmentation</b> \n",
    "3. After a quick registration, they provide an easy way for download the data through google drive\n",
    "\n",
    "<h1>Reading and Exploring The Dataset </h1><br>\n",
    "To make cloning the repository and running our code easier we included the first 100 samples in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    }
   ],
   "source": [
    "#Reading data\n",
    "print(\"Reading data...\")\n",
    "data_filenames = []\n",
    "for root, dirs, files in os.walk('data/raw_images/'):  \n",
    "    for filename in files:\n",
    "        data_filenames.append(filename)\n",
    "\n",
    "data = [np.array(Image.open('data/raw_images/' + filename)) for filename, i in zip(data_filenames , range(100))]\n",
    "print(\"Number of raw images: \\t\", end=\"\")\n",
    "print(len(data))\n",
    "\n",
    "print(\"\\nReading annotated images of segmentation...\")\n",
    "annot_filenames = []\n",
    "for root, dirs, files in os.walk('data/class_color/'):  \n",
    "    for filename in files:\n",
    "        annot_filenames.append(filename)\n",
    "        \n",
    "annot = [np.array(Image.open('data/class_color/' + filename)) for filename, i in zip(annot_filenames , range(100))]\n",
    "print(\"Number of annotated images: \\t\", end=\"\")\n",
    "print(len(annot))\n",
    "if len(data)==len(annot):\n",
    "    print(\"\\nAll raw images are annotated.\\n\")\n",
    "\n",
    "print(\"An example of raw data and its annotation: \")\n",
    "\n",
    "image_raw = data[0]\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,40))\n",
    "ax[0].imshow(image_raw)\n",
    "image_ann = annot[0]\n",
    "ax[1].imshow(image_ann)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preparation of Data</h1> <br>\n",
    "As preparation we split the data into train, validation and test samples, separate them by RGB channels, and standardize it with the help of the StandardScaler.<br>\n",
    "On a sidenote: Shuhffling the data was also inteded, but we sadly failed. Later we certainly plan to somehow solve this situation, as we find it necessary, because some of the samples that follow eachother were taken from the same video, and therefore look quite alike, both in terms of the environment and the position of the vehicles\n",
    "\n",
    "The .csv file contains metadata about the annotation, like which categories of objects the segmentation differentiates and what color reprezents each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train-validation-test parts with ratios 70-20-10\n",
    "print(\"Splitting data into training data, validation data, test data\")\n",
    "nb_samples=len(data_filenames)\n",
    "#Splitting ratios:\n",
    "valid_split = 0.2\n",
    "test_split = 0.1\n",
    "train_split = 0.7\n",
    "print(\"The ratios are: \")\n",
    "print(\"\\t train:\\t\", train_split )\n",
    "print(\"\\t validation::\\t\",valid_split )\n",
    "print(\"\\t test:\\t\",test_split)\n",
    "    \n",
    "#Splitting\n",
    "data_train = np.array(data[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "annot_train = np.array(annot[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "data_valid = data[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "annot_valid = annot[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "data_test  = data[int(nb_samples*(1-test_split)):]\n",
    "annot_test  = annot[int(nb_samples*(1-test_split)):]\n",
    "\n",
    "#Separation of axes\n",
    "red_train = []\n",
    "green_train = []\n",
    "blue_train = []\n",
    "for img in data_train:\n",
    "    image = np.array(img.ravel(), dtype='float64')\n",
    "    red_train.append(image[0::3])\n",
    "    green_train.append(image[1::3])\n",
    "    blue_train.append(image[2::3])\n",
    "\n",
    "\n",
    "#Standardizing\n",
    "scaler = StandardScaler()\n",
    "    \n",
    "print(\"\\nStandardized data:\\nRed:\")\n",
    "scaler.fit(np.reshape(red_train, (-1, 1)))\n",
    "red_std = scaler.transform(red_train)\n",
    "print(red_std)\n",
    "\n",
    "print(\"\\nGreen:\")\n",
    "scaler.fit(np.reshape(green_train, (-1,1)))\n",
    "green_std = scaler.transform(green_train)\n",
    "print(green_std)\n",
    "    \n",
    "print(\"\\nBlue:\")\n",
    "scaler.fit(np.reshape(blue_train, (-1,1)))\n",
    "blue_std = scaler.transform(blue_train)\n",
    "print(blue_std)\n",
    "\n",
    "print(\"\\nNumber of training samples:\\t\", len(data_train))\n",
    "print(\"Number of validation samples:\\t\", len(data_valid))\n",
    "print(\"Number of test samples:\\t\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading .csv file containing metadata about the segmentation\n",
    "print(\"Reading file containing metadata about the segmentation...\")\n",
    "metadf = pd.read_csv('data/categories.csv', sep=',')\n",
    "print(\"Sneak peak:\")\n",
    "metadf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Further Analyzing The Data </h1><br>\n",
    "Our aim was to gain some insight into the quality of data, like how many of the pictures do contain vehicles and how many of them do not. We also had a quick look on the whole dataset if it truly has samples from a wide range of driving conditions, and we found that it was perfect for our needs. Thus we decided, data augmentation wasn't necessary. <br>\n",
    "(Even though we found an article with great tips and tricks on how to do that here: https://medium.freecodecamp.org/image-augmentation-make-it-rain-make-it-snow-how-to-modify-a-photo-with-machine-learning-163c0cb3843f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizing subcategories into an array, and counting subcategories\n",
    "subcat = []\n",
    "no_subcat = 0\n",
    "for row in metadf.name:\n",
    "    subcat.append(row)\n",
    "no_subcat = len(subcat)\n",
    "\n",
    "#Organizing categories into an array\n",
    "cat = []\n",
    "for row in metadf.category:\n",
    "    cat.append(row)\n",
    "\n",
    "#Organizing category Ids into an array\n",
    "catid = []\n",
    "for row in metadf.catId:\n",
    "    catid.append(row)\n",
    "#Counting categories\n",
    "no_cat = 1\n",
    "act = catid[0]\n",
    "categories = [] #array containing categories without duplication\n",
    "categories.append(cat[0])\n",
    "for i in range(len(catid)):\n",
    "    if catid[i]!=act:\n",
    "        categories.append(cat[i])\n",
    "        no_cat+=1\n",
    "        act=catid[i]\n",
    "\n",
    "#Organizing subcategory RGB colors into an array\n",
    "col = []\n",
    "for row in metadf.color:\n",
    "    c = row.replace(\" \", \"\").split(',')\n",
    "    rgb = []\n",
    "    for i in c:\n",
    "        rgb.append(int(i))\n",
    "    col.append(rgb)\n",
    "\n",
    "\n",
    "print('Number of segmentation subcategories:', no_subcat)\n",
    "print('Number of segmentation categories:', no_cat, \"\\n\")\n",
    "print(\"Subcategories and their representational colors [R, G, B]: \\n\")\n",
    "for i in range(len(subcat)):\n",
    "    print(\"%30s \\t\" % subcat[i], end =\"\")\n",
    "    print(col[i])\n",
    "\n",
    "colorstodisplay = []    \n",
    "for c in col:\n",
    "    colorstodisplay.append([c[0]/255,c[1]/255,c[2]/255])\n",
    "my_cmap = mcolors.ListedColormap(colorstodisplay)\n",
    "plt.figure(figsize=(20, 0.5))\n",
    "plt.title('The Color Map (in order of subcategory)')\n",
    "plt.pcolormesh(np.arange(my_cmap.N).reshape(1, -1), cmap=my_cmap)\n",
    "plt.gca().yaxis.set_visible(False)\n",
    "plt.gca().set_xlim(0, my_cmap.N)\n",
    "plt.show()\n",
    "    \n",
    "print(\"\\nSubcategories by their categories: \\n\")\n",
    "act = cat[0]\n",
    "print(cat[0] + \":\")\n",
    "for i in range(no_subcat):\n",
    "    if cat[i] != act:\n",
    "        print(\"\\n\" + cat[i] + \":\")\n",
    "        act=cat[i]\n",
    "    print(\"\\t\\t\"+subcat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "for img in annot:\n",
    "    im = Image.fromarray(img)\n",
    "    im_rgb = im.convert('RGB')\n",
    "    colors.append(im_rgb.getcolors()) #.getcolors() returns with a tuple: [number of occurrence, [R,G,B]]\n",
    "\n",
    "#counting category and subcategory occurrences \n",
    "count_categories = [] #category occurrence\n",
    "catcounter = [] #helper for counting categroy occurrence\n",
    "count_subcategories = [] #subcategory occurrence\n",
    "count_subcategories = np.zeros(len(subcat), dtype=int)\n",
    "count_categories = np.zeros(no_cat, dtype=int)\n",
    "catcounter = np.zeros(no_cat, dtype=int)\n",
    " \n",
    "subcat_col = [] #concatenating subcategory and color arrays\n",
    "for i in range(len(subcat)):\n",
    "    subcat_col.append([subcat[i], col[i]])\n",
    "\n",
    "for imcol in colors: #iterating over images\n",
    "    catcounter = np.zeros(no_cat, dtype=int)\n",
    "    for j in range(len(imcol)): #iterating over colors of one image   \n",
    "        for i in range(len(subcat_col)): #iterating over subcategory colors\n",
    "            if(tuple(subcat_col[i][1]) == imcol[j][1]): #if found\n",
    "                count_subcategories[i] += 1 #increasing subcategory counter by 1\n",
    "                catcounter[catid[i]] = 1 #helper for counting categories\n",
    "    for c in range(len(catcounter)): #increasing ech category found in the colors of one image\n",
    "        count_categories[c] += catcounter[c]\n",
    "        \n",
    "print(\"An example of segmentation\")\n",
    "print(\"\\tWhere (RGB) depicts subcategory: \")\n",
    "for row in colors[0]:\n",
    "    print(\"\\n\\t\\t\", row[1], \" depicts:  \", end=\"\")\n",
    "    for i in range(len(subcat_col)): #iterating over subcategory colors\n",
    "            if(tuple(subcat_col[i][1]) == row[1]): #if found\n",
    "                print(\"  \", subcat_col[i][0], end=\"\")\n",
    "                \n",
    "image = annot_train[0]\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Categories and the number of pictures they occur in (out of \", len(annot) , \" samples):\")\n",
    "for i in range(no_cat):\n",
    "    print(categories[i] + \": \", end='')\n",
    "    print(count_categories[i])\n",
    "print(\"Conclusion: most of the data has some kind of vehicle on them. Which is good, as it is our main region of interest.\")\n",
    "        \n",
    "print(\"\\nSubcategories and the number of pictures they occur in (out of \", len(annot) , \"samples):\")\n",
    "for i in range(no_subcat):\n",
    "    print(subcat[i] + \": \", end='')\n",
    "    print(count_subcategories[i])\n",
    "    \n",
    "print(\"hello darkness my old friend\")\n",
    "\n",
    "print(\"\\n\\nSome fancy exploding pie charts visualizing some of the earlier gained statistical data:\")\n",
    "labels = 'Pictures with trucks on them', 'No trucks :('\n",
    "sizes = [count_subcategories[-1],len(annot)-count_subcategories[-1]]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = 'Pictures with person object on them', 'Pictures with no person object on them'\n",
    "index=0\n",
    "for sc in range(len(subcat)):\n",
    "    if subcat[sc] == \"person\":\n",
    "        index = sc\n",
    "        break\n",
    "sizes = [count_subcategories[index],len(annot)-count_subcategories[index]]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n",
    "#...and then we realised these pie charts aren't as informative as we wished they would be, so we stopped making them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
