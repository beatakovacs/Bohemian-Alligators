{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file containing metadata about the segmentation...\n",
      "Number of segmentation subcategories: 41\n",
      "Number of segmentation categories: 8 \n",
      "\n",
      "Subcategories and their representational colors [R, G, B]: \n",
      "\n",
      "                     unlabeled \t0    [0, 0, 0]\n",
      "                       dynamic \t1    [111, 74, 0]\n",
      "                   ego vehicle \t2    [0, 0, 0]\n",
      "                        ground \t3    [81, 0, 81]\n",
      "                        static \t4    [0, 0, 0]\n",
      "                       parking \t5    [250, 170, 160]\n",
      "                    rail track \t6    [230, 150, 140]\n",
      "                          road \t7    [128, 64, 128]\n",
      "                      sidewalk \t8    [244, 35, 232]\n",
      "                        bridge \t9    [150, 100, 100]\n",
      "                      building \t10    [70, 70, 70]\n",
      "                         fence \t11    [190, 153, 153]\n",
      "                        garage \t12    [180, 100, 180]\n",
      "                    guard rail \t13    [180, 165, 180]\n",
      "                        tunnel \t14    [150, 120, 90]\n",
      "                         wall  \t15    [102, 102, 156]\n",
      "                        banner \t16    [250, 170, 100]\n",
      "                     billboard \t17    [220, 220, 250]\n",
      "                  lane divider \t18    [255, 165, 0]\n",
      "                  parking sign \t19    [220, 20, 60]\n",
      "                          pole \t20    [153, 153, 153]\n",
      "                     polegroup \t21    [153, 153, 153]\n",
      "                  street light \t22    [220, 220, 100]\n",
      "                  traffic cone \t23    [255, 70, 0]\n",
      "                traffic device \t24    [220, 220, 220]\n",
      "                 traffic light \t25    [250, 170, 30]\n",
      "                  traffic sign \t26    [220, 220, 0]\n",
      "            traffic sign frame \t27    [250, 170, 250]\n",
      "                       terrain \t28    [152, 251, 152]\n",
      "                    vegetation \t29    [107, 142, 35]\n",
      "                           sky \t30    [70, 130, 180]\n",
      "                        person \t31    [220, 20, 60]\n",
      "                         rider \t32    [255, 0, 0]\n",
      "                       bicycle \t33    [119, 11, 32]\n",
      "                           bus \t34    [0, 60, 100]\n",
      "                           car \t35    [0, 0, 142]\n",
      "                       caravan \t36    [0, 0, 90]\n",
      "                    motorcycle \t37    [0, 0, 230]\n",
      "                       trailer \t38    [0, 0, 110]\n",
      "                         train \t39    [0, 80, 100]\n",
      "                         truck \t40    [0, 0, 70]\n"
     ]
    }
   ],
   "source": [
    "#Reading .csv file containing metadata about the segmentation\n",
    "print(\"Reading file containing metadata about the segmentation...\")\n",
    "metadf = pd.read_csv('dataset/categories.csv', sep=',')\n",
    "\n",
    "#Organizing subcategories into an array, and counting subcategories\n",
    "subcat = []\n",
    "no_subcat = 0\n",
    "for row in metadf.name:\n",
    "    subcat.append(row)\n",
    "no_subcat = len(subcat)\n",
    "\n",
    "#Organizing categories into an array\n",
    "cat = []\n",
    "for row in metadf.category:\n",
    "    cat.append(row)\n",
    "\n",
    "#Organizing category Ids into an array\n",
    "catid = []\n",
    "for row in metadf.catId:\n",
    "    catid.append(row)\n",
    "#Counting categories\n",
    "no_cat = 1\n",
    "act = catid[0]\n",
    "categories = [] #array containing categories without duplication\n",
    "categories.append(cat[0])\n",
    "for i in range(len(catid)):\n",
    "    if catid[i]!=act:\n",
    "        categories.append(cat[i])\n",
    "        no_cat+=1\n",
    "        act=catid[i]\n",
    "\n",
    "#Organizing subcategory RGB colors into an array\n",
    "col = []\n",
    "for row in metadf.color:\n",
    "    c = row.replace(\" \", \"\").split(',')\n",
    "    rgb = []\n",
    "    for i in c:\n",
    "        rgb.append(int(i))\n",
    "    col.append(rgb)\n",
    "\n",
    "\n",
    "print('Number of segmentation subcategories:', no_subcat)\n",
    "print('Number of segmentation categories:', no_cat, \"\\n\")\n",
    "print(\"Subcategories and their representational colors [R, G, B]: \\n\")\n",
    "for i in range(len(subcat)):\n",
    "    print(\"%30s \\t\" % subcat[i], end =\"\")\n",
    "    print(i, \"  \", col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/67/9f795649f1173b18851941e288035695386ee44c33bb0960832550f8a236/natsort-5.5.0-py2.py3-none-any.whl\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-5.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading filenames\n",
    "\n",
    "data_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/raw_images/'):  \n",
    "    for filename in files:\n",
    "        data_filenames.append(filename)\n",
    "\n",
    "annot_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/class_color/'):  \n",
    "    for filename in files:\n",
    "        annot_filenames.append(filename)\n",
    "        \n",
    "catid_annot_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/catid_annot/'):  \n",
    "    for filename in files:\n",
    "        catid_annot_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcategory-Id-Annotation Files Already Exist\n"
     ]
    }
   ],
   "source": [
    "#checking for files in the corresponding folder\n",
    "catid_annot_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/catid_annot/'):  \n",
    "    for filename in files:\n",
    "        catid_annot_filenames.append('dataset/catid_annot/'+filename)\n",
    "\n",
    "#if all the annotationfiles exist, there's no need to create them\n",
    "if len(catid_annot_filenames) == len(annot_filenames):\n",
    "    print('Subcategory-Id-Annotation Files Already Exist')\n",
    "\n",
    "#if not, then the .png annotation files should be loaded, \n",
    "#the matrices should be created, and they should be serialized\n",
    "if len(catid_annot_filenames) != len(annot_filenames):\n",
    "    print('Subcategory-Id-Annotation Files DO NOT Exist')\n",
    "    for image in range(len(annot_filenames)): #iterationg over annotation-image filenames\n",
    "        if os.path.exists('dataset/catid_annot/' + data_filenames[image]):\n",
    "            print(\"ez mar kesz\")\n",
    "        else:\n",
    "            print(image)\n",
    "            filename = annot_filenames[image]\n",
    "            #loading .png image, converting it to have RGB channels only\n",
    "            img = np.array(Image.open('dataset/class_color/' + filename).convert('RGB'))\n",
    "            catid_annot_img = [] #this is gonna be our new matrice\n",
    "            for i, row in enumerate(img): #iterating over rows\n",
    "                catid_row = []\n",
    "                for j, pixel in enumerate(row): #iterating over pixels\n",
    "                    catid_row.append(col.index(list(row[j]))) #appending the corresponding subcategory id\n",
    "                catid_annot_img.append(catid_row) \n",
    "         \n",
    "            #saving the matrices\n",
    "            np.array(catid_annot_img).tofile('dataset/catid_annot/' + data_filenames[image])\n",
    "    \n",
    "        #double checking if all the matrices have been serialized    \n",
    "        for root, dirs, files in os.walk('dataset/catid_annot/'):  \n",
    "            for filename in files:\n",
    "                catid_annot_filenames.append('dataset/catid_annot/'+filename)\n",
    "        if len(catid_annot_filenames) == len(annot_filenames):\n",
    "            print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training data, validation data, test data\n",
      "The ratios are: \n",
      "\t train:\t 0.7\n",
      "\t validation:\t 0.2\n",
      "\t test:\t 0.1\n",
      "\n",
      "Number of training samples:\t 142\n",
      "Number of validation samples:\t 40\n",
      "Number of test samples:\t 21\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train-validation-test parts with ratios 70-20-10\n",
    "print(\"Splitting data into training data, validation data, test data\")\n",
    "nb_samples=len(data_filenames)\n",
    "#Splitting ratios:\n",
    "valid_split = 0.2\n",
    "test_split = 0.1\n",
    "train_split = 0.7\n",
    "print(\"The ratios are: \")\n",
    "print(\"\\t train:\\t\", train_split )\n",
    "print(\"\\t validation:\\t\",valid_split )\n",
    "print(\"\\t test:\\t\",test_split)\n",
    "    \n",
    "#Splitting\n",
    "#The serialized annotation files are on the same name but in a different directory,\n",
    "#so we only need to split one of the arrays.\n",
    "data_train = np.array(data_filenames[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "data_valid = data_filenames[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "data_test  = data_filenames[int(nb_samples*(1-test_split)):]\n",
    "\n",
    "print(\"\\nNumber of training samples:\\t\", len(data_train))\n",
    "print(\"Number of validation samples:\\t\", len(data_valid))\n",
    "print(\"Number of test samples:\\t\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
