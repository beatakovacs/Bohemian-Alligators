{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\"Louis, I think this is the beginning of a beautiful friendship.\"</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Number of raw images: \t100\n",
      "\n",
      "Reading annotated images of segmentation...\n",
      "Number of annotated images: \t100\n",
      "\n",
      "All raw images are annotated.\n",
      "\n",
      "Splitting data into training data, validation data, test data\n",
      "The ratios are: \n",
      "\t train:\t 0.7\n",
      "\t validation::\t 0.2\n",
      "\t test:\t 0.1\n",
      "\n",
      "Standardized data:\n",
      "Red:\n",
      "[[ 0.70883338  0.75526445  0.77074147 ... -1.0865011  -1.11745515\n",
      "  -1.13293217]\n",
      " [-0.99363897 -1.009116   -1.05554706 ... -0.82339174 -0.88529982\n",
      "  -0.93173089]\n",
      " [-1.78296707 -1.78296707 -1.79844409 ... -0.73052961 -0.68409855\n",
      "  -0.6531445 ]\n",
      " ...\n",
      " [-0.52932833 -0.49837429 -0.46742025 ...  1.45173041  1.45173041\n",
      "   1.45173041]\n",
      " [-0.48289727 -0.48289727 -0.48289727 ...  1.54459254  1.54459254\n",
      "   1.54459254]\n",
      " [-0.54480535 -0.54480535 -0.54480535 ...  1.62197764  1.60650062\n",
      "   1.5910236 ]]\n",
      "\n",
      "Green:\n",
      "[[ 7.46722452e-01  7.90557744e-01  8.05169507e-01 ... -1.16741860e+00\n",
      "  -1.19664213e+00 -1.21125390e+00]\n",
      " [-1.07974802e+00 -1.09435979e+00 -1.13819508e+00 ... -1.06513626e+00\n",
      "  -1.12358331e+00 -1.16741860e+00]\n",
      " [-1.92723032e+00 -1.92723032e+00 -1.94184209e+00 ... -9.77465675e-01\n",
      "  -9.33630384e-01 -9.04406856e-01]\n",
      " ...\n",
      " [-4.23127926e-02 -1.30892650e-02  1.61342626e-02 ...  1.14124007e+00\n",
      "   1.14124007e+00  1.14124007e+00]\n",
      " [ 1.52249881e-03  1.52249881e-03  1.52249881e-03 ...  1.22891066e+00\n",
      "   1.22891066e+00  1.22891066e+00]\n",
      " [ 1.52249881e-03  1.52249881e-03  1.52249881e-03 ...  1.30196948e+00\n",
      "   1.28735771e+00  1.27274595e+00]]\n",
      "\n",
      "Blue:\n",
      "[[ 1.02457695  1.06390827  1.07701871 ... -0.96821013 -0.99443101\n",
      "  -1.00754145]\n",
      " [-1.33530248 -1.34841292 -1.38774425 ... -0.87643704 -0.9288788\n",
      "  -0.96821013]\n",
      " [-1.87283058 -1.87283058 -1.88594102 ... -1.05998322 -1.02065189\n",
      "  -0.99443101]\n",
      " ...\n",
      " [ 0.65748459  0.68370547  0.70992636 ...  0.64437415  0.64437415\n",
      "   0.64437415]\n",
      " [ 0.81480989  0.81480989  0.81480989 ...  0.59193239  0.59193239\n",
      "   0.59193239]\n",
      " [ 0.80169945  0.80169945  0.80169945 ...  0.63126371  0.61815327\n",
      "   0.60504283]]\n",
      "\n",
      "Number of training samples:\t 70\n",
      "Number of validation samples:\t 20\n",
      "Number of test samples:\t 10\n"
     ]
    }
   ],
   "source": [
    "#Reading data\n",
    "print(\"Reading data...\")\n",
    "data_filenames = []\n",
    "for root, dirs, files in os.walk('data/raw_images/'):  \n",
    "    for filename in files:\n",
    "        data_filenames.append(filename)\n",
    "\n",
    "data = [np.array(Image.open('data/raw_images/' + filename)) for filename in data_filenames]\n",
    "print(\"Number of raw images: \\t\", end=\"\")\n",
    "print(len(data))\n",
    "\n",
    "print(\"\\nReading annotated images of segmentation...\")\n",
    "annot_filenames = []\n",
    "for root, dirs, files in os.walk('data/class_color/'):  \n",
    "    for filename in files:\n",
    "        annot_filenames.append(filename)\n",
    "        \n",
    "annot = [np.array(Image.open('data/class_color/' + filename)) for filename in annot_filenames ]\n",
    "print(\"Number of annotated images: \\t\", end=\"\")\n",
    "print(len(annot))\n",
    "if len(data)==len(annot):\n",
    "    print(\"\\nAll raw images are annotated.\\n\")\n",
    "\n",
    "#Splitting data into train-validation-test parts with ratios 70-20-10\n",
    "print(\"Splitting data into training data, validation data, test data\")\n",
    "nb_samples=len(data_filenames)\n",
    "#Splitting ratios:\n",
    "valid_split = 0.2\n",
    "test_split = 0.1\n",
    "train_split = 0.7\n",
    "print(\"The ratios are: \")\n",
    "print(\"\\t train:\\t\", train_split )\n",
    "print(\"\\t validation::\\t\",valid_split )\n",
    "print(\"\\t test:\\t\",test_split)\n",
    "    \n",
    "#Splitting\n",
    "data_train = np.array(data[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "annot_train = np.array(annot[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "data_valid = data[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "annot_valid = annot[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "data_test  = data[int(nb_samples*(1-test_split)):]\n",
    "annot_test  = annot[int(nb_samples*(1-test_split)):]\n",
    "\n",
    "#Separation of axes (RGB channels)\n",
    "red_train = []\n",
    "green_train = []\n",
    "blue_train = []\n",
    "for img in data_train:\n",
    "    image = np.array(img.ravel(), dtype='float64')\n",
    "    red_train.append(image[0::3])\n",
    "    green_train.append(image[1::3])\n",
    "    blue_train.append(image[2::3])\n",
    "\n",
    "\n",
    "#Standardizing\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.reshape(red_train, (-1, 1)))\n",
    "red_std = scaler.transform(red_train)\n",
    "\n",
    "scaler.fit(np.reshape(green_train, (-1,1)))\n",
    "green_std = scaler.transform(green_train)\n",
    "\n",
    "scaler.fit(np.reshape(blue_train, (-1,1)))\n",
    "blue_std = scaler.transform(blue_train)\n",
    "\n",
    "print(\"\\nNumber of training samples:\\t\", len(data_train))\n",
    "print(\"Number of validation samples:\\t\", len(data_valid))\n",
    "print(\"Number of test samples:\\t\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications import imagenet_utils\n",
    "from tensorflow.python.client import device_lib\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "# Device check\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    return imagenet_utils.preprocess_input(x, mode='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(images, labels, batch_size=32, dim=(1024, 2048), n_classes=34, shuffle=True):\n",
    "    # Initialization\n",
    "    data_size = len(images)\n",
    "    nbatches = data_size // batch_size\n",
    "    list_IDs = np.arange(data_size)\n",
    "    indices = list_IDs\n",
    "    \n",
    "    # Data generation\n",
    "    while True:\n",
    "        if shuffle == True:\n",
    "            np.random.shuffle(indices)\n",
    "        for index in range(nbatches):\n",
    "            batch_indices = indices[index*batch_size:(index+1)*batch_size]\n",
    "\n",
    "            X = np.empty((batch_size, *dim, 3))\n",
    "            y_semseg = np.empty((batch_size, *dim), dtype=int)\n",
    "\n",
    "            for i, ID in enumerate(batch_indices):\n",
    "                image = cv2.resize(np.array(imageio.imread(images[ID]), dtype=np.uint8), dim[1::-1])\n",
    "                label = cv2.resize(imageio.imread(labels[ID]), dim[1::-1], interpolation=cv2.INTER_NEAREST)\n",
    "                X[i,] = image\n",
    "                y_semseg[i] = label\n",
    "            yield (preprocess_input(X), to_categorical(y_semseg, num_classes=n_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
