{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segmentation subcategories: 41\n",
      "Number of segmentation categories: 8 \n",
      "\n",
      "Subcategories and their representational colors [R, G, B]: \n",
      "\n",
      "                     unlabeled \t0    [0, 0, 0]\n",
      "                       dynamic \t1    [111, 74, 0]\n",
      "                   ego vehicle \t2    [0, 0, 0]\n",
      "                        ground \t3    [81, 0, 81]\n",
      "                        static \t4    [0, 0, 0]\n",
      "                       parking \t5    [250, 170, 160]\n",
      "                    rail track \t6    [230, 150, 140]\n",
      "                          road \t7    [128, 64, 128]\n",
      "                      sidewalk \t8    [244, 35, 232]\n",
      "                        bridge \t9    [150, 100, 100]\n",
      "                      building \t10    [70, 70, 70]\n",
      "                         fence \t11    [190, 153, 153]\n",
      "                        garage \t12    [180, 100, 180]\n",
      "                    guard rail \t13    [180, 165, 180]\n",
      "                        tunnel \t14    [150, 120, 90]\n",
      "                         wall  \t15    [102, 102, 156]\n",
      "                        banner \t16    [250, 170, 100]\n",
      "                     billboard \t17    [220, 220, 250]\n",
      "                  lane divider \t18    [255, 165, 0]\n",
      "                  parking sign \t19    [220, 20, 60]\n",
      "                          pole \t20    [153, 153, 153]\n",
      "                     polegroup \t21    [153, 153, 153]\n",
      "                  street light \t22    [220, 220, 100]\n",
      "                  traffic cone \t23    [255, 70, 0]\n",
      "                traffic device \t24    [220, 220, 220]\n",
      "                 traffic light \t25    [250, 170, 30]\n",
      "                  traffic sign \t26    [220, 220, 0]\n",
      "            traffic sign frame \t27    [250, 170, 250]\n",
      "                       terrain \t28    [152, 251, 152]\n",
      "                    vegetation \t29    [107, 142, 35]\n",
      "                           sky \t30    [70, 130, 180]\n",
      "                        person \t31    [220, 20, 60]\n",
      "                         rider \t32    [255, 0, 0]\n",
      "                       bicycle \t33    [119, 11, 32]\n",
      "                           bus \t34    [0, 60, 100]\n",
      "                           car \t35    [0, 0, 142]\n",
      "                       caravan \t36    [0, 0, 90]\n",
      "                    motorcycle \t37    [0, 0, 230]\n",
      "                       trailer \t38    [0, 0, 110]\n",
      "                         train \t39    [0, 80, 100]\n",
      "                         truck \t40    [0, 0, 70]\n"
     ]
    }
   ],
   "source": [
    "#Reading .csv file containing metadata about the segmentation\n",
    "metadf = pd.read_csv('dataset/categories.csv', sep=',')\n",
    "\n",
    "#Organizing subcategories into an array, and counting subcategories\n",
    "subcat = []\n",
    "no_subcat = 0\n",
    "for row in metadf.name:\n",
    "    subcat.append(row)\n",
    "no_subcat = len(subcat)\n",
    "\n",
    "#Organizing categories into an array\n",
    "cat = []\n",
    "for row in metadf.category:\n",
    "    cat.append(row)\n",
    "\n",
    "#Organizing category Ids into an array\n",
    "catid = []\n",
    "for row in metadf.catId:\n",
    "    catid.append(row)\n",
    "#Counting categories\n",
    "no_cat = 1\n",
    "act = catid[0]\n",
    "categories = [] #array containing categories without duplication\n",
    "categories.append(cat[0])\n",
    "for i in range(len(catid)):\n",
    "    if catid[i]!=act:\n",
    "        categories.append(cat[i])\n",
    "        no_cat+=1\n",
    "        act=catid[i]\n",
    "\n",
    "#Organizing subcategory RGB colors into an array\n",
    "col = []\n",
    "for row in metadf.color:\n",
    "    c = row.replace(\" \", \"\").split(',')\n",
    "    rgb = []\n",
    "    for i in c:\n",
    "        rgb.append(int(i))\n",
    "    col.append(rgb)\n",
    "\n",
    "\n",
    "print('Number of segmentation subcategories:', no_subcat)\n",
    "print('Number of segmentation categories:', no_cat, \"\\n\")\n",
    "print(\"Subcategories and their representational colors [R, G, B]: \\n\")\n",
    "for i in range(len(subcat)):\n",
    "    print(\"%30s \\t\" % subcat[i], end =\"\")\n",
    "    print(i, \"  \", col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading filenames\n",
    "\n",
    "data_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/raw_images/'):  \n",
    "    for filename in files:\n",
    "        data_filenames.append(filename)\n",
    "\n",
    "annot_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/class_color/'):  \n",
    "    for filename in files:\n",
    "        annot_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcategory-Id-Annotation Files Already Exist\n"
     ]
    }
   ],
   "source": [
    "#checking for files in the corresponding folder\n",
    "catid_annot_filenames = []\n",
    "for root, dirs, files in os.walk('dataset/catid_annot/'):  \n",
    "    for filename in files:\n",
    "        catid_annot_filenames.append('dataset/catid_annot/'+filename)\n",
    "\n",
    "#if all the annotationfiles exist, there's no need to create them\n",
    "if len(catid_annot_filenames) == len(annot_filenames):\n",
    "    print('Subcategory-Id-Annotation Files Already Exist')\n",
    "\n",
    "#if not, then the .png annotation files should be loaded, \n",
    "#the matrices should be created, and they should be serialized\n",
    "if len(catid_annot_filenames) != len(annot_filenames):\n",
    "    print('Subcategory-Id-Annotation Files DO NOT Exist')\n",
    "    \n",
    "    for image in range(len(annot_filenames)): #iterationg over annotation-image filenames\n",
    "        filename = annot_filenames[image]\n",
    "        #loading .png image, converting it to have RGB channels only\n",
    "        img = np.array(Image.open('dataset/class_color/' + filename).convert('RGB'))\n",
    "        catid_annot_img = [] #this is gonna be our new matrice\n",
    "        for i, row in enumerate(img): #iterating over rows\n",
    "            catid_row = []\n",
    "            for j, pixel in enumerate(row): #iterating over pixels\n",
    "                catid_row.append(col.index(list(row[j]))) #appending the corresponding subcategory id\n",
    "            catid_annot_img.append(catid_row) \n",
    "         \n",
    "        #saving the matrices\n",
    "        np.array(catid_annot_img).tofile('dataset/catid_annot/' + data_filenames[image])\n",
    "    \n",
    "    #double checking if all the matrices have been serialized    \n",
    "    for root, dirs, files in os.walk('dataset/catid_annot/'):  \n",
    "        for filename in files:\n",
    "            catid_annot_filenames.append('dataset/catid_annot/'+filename)\n",
    "    if len(catid_annot_filenames) == len(annot_filenames):\n",
    "        print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training data, validation data, test data\n",
      "The ratios are: \n",
      "\t train:\t 0.7\n",
      "\t validation:\t 0.15\n",
      "\t test:\t 0.15\n",
      "\n",
      "Number of training samples:\t 700\n",
      "Number of validation samples:\t 150\n",
      "Number of test samples:\t 150\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train-validation-test parts with ratios 70-20-10\n",
    "print(\"Splitting data into training data, validation data, test data\")\n",
    "nb_samples=len(data_filenames)\n",
    "#Splitting ratios:\n",
    "valid_split = 0.15\n",
    "test_split = 0.15\n",
    "train_split = 0.7\n",
    "print(\"The ratios are: \")\n",
    "print(\"\\t train:\\t\", train_split )\n",
    "print(\"\\t validation:\\t\",valid_split )\n",
    "print(\"\\t test:\\t\",test_split)\n",
    "    \n",
    "#Splitting\n",
    "#The serialized annotation files are on the same name but in a different directory,\n",
    "#so we only need to split one of the arrays.\n",
    "data_train = np.array(data_filenames[0:int(nb_samples*(1-valid_split-test_split))])\n",
    "data_valid = data_filenames[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "data_test  = data_filenames[int(nb_samples*(1-test_split)):]\n",
    "\n",
    "print(\"\\nNumber of training samples:\\t\", len(data_train))\n",
    "print(\"Number of validation samples:\\t\", len(data_valid))\n",
    "print(\"Number of test samples:\\t\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import cv2\n",
    "import imageio\n",
    "import json\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications import imagenet_utils\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    return imagenet_utils.preprocess_input(x, mode='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(filenames, batch_size=32, dim=(720, 1280), n_classes=41, shuffle=True):\n",
    "    # Initialization\n",
    "    data_size = len(filenames)\n",
    "    nbatches = data_size // batch_size\n",
    "    list_IDs = np.arange(data_size)\n",
    "    indices = list_IDs\n",
    "    # Data generation\n",
    "    while True:\n",
    "        try:\n",
    "            if shuffle == True:\n",
    "                np.random.shuffle(indices) #shuffling when Shuffle parameter is True\n",
    "\n",
    "            for index in range(nbatches):\n",
    "                batch_indices = indices[index*batch_size:(index+1)*batch_size]\n",
    "\n",
    "                X = np.empty((batch_size, *dim, 3))\n",
    "                y_semseg = np.empty((batch_size, *dim), dtype=int)\n",
    "\n",
    "                for i, ID in enumerate(batch_indices):\n",
    "                    #reading in the raw image on the fly\n",
    "                    image = cv2.resize(np.array(Image.open('dataset/raw_images/' + filenames[ID]), dtype=np.uint8), dim[1::-1])\n",
    "                    #loading in the serialized annotation file on the fly\n",
    "                    catid_annot_img = np.array(Image.open('dataset/catid_annot/'+ filenames[ID][:-3] + \"png\"),dtype=np.int64)\n",
    "                    catid_annot_img = np.reshape(catid_annot_img, (720, 1280))\n",
    "                    label = cv2.resize(catid_annot_img, dim[1::-1], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                    X[i,] = image\n",
    "                    y_semseg[i] = label\n",
    "\n",
    "                yield (preprocess_input(X), to_categorical(y_semseg, num_classes=n_classes))\n",
    "        except StopIteration as e:\n",
    "            print(e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640)\n"
     ]
    }
   ],
   "source": [
    "#Parameters for the data generator\n",
    "batch_size = 4\n",
    "data_shape= imageio.imread('dataset/raw_images/' + data_train[0]).shape[:2]\n",
    "data_shape= (int(data_shape[0]/2), int(data_shape[1]/2))\n",
    "print(data_shape)\n",
    "classes = no_subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a data generator for training and validating\n",
    "#train_generator = data_generator(data_train, batch_size=batch_size, dim=data_shape, n_classes=classes)\n",
    "#val_generator = data_generator(data_valid, batch_size=batch_size, dim=data_shape, n_classes=classes)\n",
    "test_generator = data_generator(data_test, batch_size=batch_size, dim=data_shape, n_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as models\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "\n",
    "def get_unet_128_ulite(input_shape=(360, 640, 3),\n",
    "                 num_classes=41, optimizer='adam'):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 128\n",
    " \n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    " \n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    " \n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    " \n",
    "    # 16\n",
    " \n",
    "    # 16\n",
    " \n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    " \n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = keras.layers.concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    " \n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = keras.layers.concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    " \n",
    "    classify = Conv2D(num_classes, (1, 1), padding='valid')(up1)\n",
    "    classify = Activation('softmax')(classify)\n",
    " \n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer= optimizer,\n",
    "                  metrics=['accuracy'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "semseg_model = get_unet_128_ulite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "semseg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semseg_model.load_weights('model_weights/model.36-0.9417.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
      "Building wheels for collected packages: progressbar\n",
      "  Running setup.py bdist_wheel for progressbar: started\n",
      "  Running setup.py bdist_wheel for progressbar: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Asus Gamer\\AppData\\Local\\pip\\Cache\\wheels\\c0\\e9\\6b\\ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import progressbar\n",
    "import itertools\n",
    "\n",
    "progress = progressbar.ProgressBar(widgets=[progressbar.Bar('=', '[', ']'), ' ',\n",
    "                                            progressbar.Percentage(), ' ',\n",
    "                                            progressbar.ETA()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unlabeled', 'dynamic', 'ego vehicle', 'ground', 'static', 'parking', 'rail track', 'road', 'sidewalk', 'bridge', 'building', 'fence', 'garage', 'guard rail', 'tunnel', 'wall ', 'banner', 'billboard', 'lane divider', 'parking sign', 'pole', 'polegroup', 'street light', 'traffic cone', 'traffic device', 'traffic light', 'traffic sign', 'traffic sign frame', 'terrain', 'vegetation', 'sky', 'person', 'rider', 'bicycle', 'bus', 'car', 'caravan', 'motorcycle', 'trailer', 'train', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = np.zeros_like(subcat, dtype=int)\n",
    "union = np.zeros_like(subcat, dtype=int)\n",
    "support = np.zeros_like(subcat, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==========================================================] 100% Time: 0:03:33\n"
     ]
    }
   ],
   "source": [
    "for i in progress(range(len(data_test)//batch_size)):\n",
    "    image_batch, label_batch = next(test_generator)\n",
    "    pred_labels_batch = semseg_model.predict_on_batch(image_batch)\n",
    "    label_flat = np.argmax(label_batch, -1).flatten()\n",
    "    pred_label_flat = np.argmax(pred_labels_batch, -1).flatten()\n",
    "    \n",
    "    for i, l in enumerate(subcat):\n",
    "        pred_mask = (pred_label_flat == i)\n",
    "        label_mask = (label_flat == i)\n",
    "   #     print(np.sum(np.logical_and(pred_mask, label_mask)))\n",
    " #       print(pred_mask, \"\\n\", label_mask)\n",
    "        intersection[i] += np.sum(np.logical_and(pred_mask, label_mask))\n",
    "        union[i] += np.sum(np.logical_or(pred_mask, label_mask))\n",
    "        support[i] += np.sum(label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection over Union\n",
      "unlabeled            - 0.478\n",
      "dynamic              - 0.000\n",
      "ego vehicle          - nan\n",
      "ground               - 0.000\n",
      "static               - nan\n",
      "parking              - 0.000\n",
      "rail track           - nan\n",
      "road                 - 0.697\n",
      "sidewalk             - 0.095\n",
      "bridge               - 0.037\n",
      "building             - 0.524\n",
      "fence                - 0.020\n",
      "garage               - nan\n",
      "guard rail           - 0.165\n",
      "tunnel               - 0.000\n",
      "wall                 - 0.000\n",
      "banner               - 0.000\n",
      "billboard            - 0.000\n",
      "lane divider         - nan\n",
      "parking sign         - 0.021\n",
      "pole                 - 0.153\n",
      "polegroup            - nan\n",
      "street light         - 0.000\n",
      "traffic cone         - 0.000\n",
      "traffic device       - 0.000\n",
      "traffic light        - 0.053\n",
      "traffic sign         - 0.093\n",
      "traffic sign frame   - 0.078\n",
      "terrain              - 0.171\n",
      "vegetation           - 0.677\n",
      "sky                  - 0.912\n",
      "person               - nan\n",
      "rider                - 0.000\n",
      "bicycle              - 0.000\n",
      "bus                  - 0.000\n",
      "car                  - 0.472\n",
      "caravan              - 0.000\n",
      "motorcycle           - 0.000\n",
      "trailer              - 0.000\n",
      "train                - nan\n",
      "truck                - 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(\"Intersection over Union\")\n",
    "for i, l in enumerate(subcat):\n",
    "    print('{:20s} - {:3.3f}'.format(l, intersection[i]/union[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
